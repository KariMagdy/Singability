{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded\n"
     ]
    }
   ],
   "source": [
    "# Load required packages\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import threading\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print \"Packages loaded\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for feature extraction\n",
    "class arayi(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    # Get list of tracks for extraction\n",
    "    def getTrackList(self,pathToTrack,listBool,trackName):\n",
    "        if listBool == False:\n",
    "            self.filelist=[]\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    tName,language=line[2].replace(\"_\",\" \").lstrip().rstrip(),line[6].rstrip()\n",
    "                    if (tName == trackName and language == \"EN\"):\n",
    "                        self.filelist.append(line[1])\n",
    "            return self.filelist\n",
    "        else:\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "\n",
    "    def getLabelList(self,pathToTrack,listBool,trackName):\n",
    "        if listBool == False:\n",
    "            self.filelist=[]\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    if (line[2].replace(\"_\",\" \").lstrip().rstrip() == trackName and line[6].rstrip() == \"EN\"):\n",
    "                        self.filelist.append(line[5])\n",
    "            return self.filelist\n",
    "        else:\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "        \n",
    "    def getTracksAndLabels(self,pathtoTrack,listBool,trackName):\n",
    "        self.dataDict={}\n",
    "        if listBool == False:\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    if (line[2].replace(\"_\",\" \").lstrip().rstrip() == trackName and line[6].rstrip() == \"EN\"):\n",
    "                        self.dataDict[line[1]]=line[5]\n",
    "            return self.dataDict\n",
    "        else:\n",
    "            self.filelist=[]\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "        \n",
    "    # Extract Melodic Contours from Dataset\n",
    "    def extractMelody(self, pathToTrack,trackList):\n",
    "        self.extractStatus = 0.0\n",
    "        pathToTrack = pathToTrack+\"raw/\"\n",
    "        # Extracts contour for a track snd saves output for each track\n",
    "        for track in trackList:\n",
    "            self.trackOut = \"/Users/nus/singability_data/contours/%s.yml\" % track.split(\".\")[0]\n",
    "            os.system(\"essentia_streaming_predominantpitchmelodia %s %s\" % (pathToTrack+track+\".m4a\", self.trackOut))\n",
    "            if float(trackList.index(track)+1)/len(trackList) > self.extractStatus:\n",
    "                print \"Extracting...%s %% complete.\" % (self.extractStatus*100)\n",
    "                self.extractStatus += 0.33\n",
    "                \n",
    "    def cleanTrack(self,labelList):\n",
    "        df = pickle.load(open(\"/Users/nus/singability_data/letItGo.pkl\",\"rb\"))\n",
    "        df=df.transpose()\n",
    "        self.lList=[]\n",
    "        for col in df:\n",
    "            numNull=df[col].isnull().sum()\n",
    "            if numNull > 60:\n",
    "                df.drop(col,1,inplace=True)\n",
    "                self.lList.append(col)\n",
    "        df.fillna(0)\n",
    "        labelList=[x for i,x in enumerate(labelList) if i not in lList]\n",
    "        return (df,labelList)\n",
    "\n",
    "    def makeContourDataframe(self,pathToContours):\n",
    "        cList=os.listdir(pathToContours)\n",
    "        self.contourMatrix = {}\n",
    "        for contour in cList:\n",
    "            if \".yml\" not in contour:\n",
    "                continue\n",
    "            x=list(open(pathToContours+contour,\"r\"))\n",
    "            x=map(float,x[7].lstrip().replace(\"pitch: \",\"\").replace(\"[\",\"\").replace(\"]\",\"\").split(\",\"))\n",
    "            self.contourMatrix[contour.replace(\".yml\",\"\")]=x\n",
    "        df = pd.DataFrame.from_dict(self.contourMatrix,orient=\"index\")\n",
    "        return df\n",
    "\n",
    "    def excludeDataframeTracks(self,theDf,window,lList,tList):\n",
    "        indexes=[]\n",
    "        for col in theDf:\n",
    "            numNull=theDf[col].isnull().sum()\n",
    "            if numNull > window:\n",
    "                theDf.drop(col,1,inplace=True)\n",
    "                indexes.append(col)\n",
    "        for index in sorted(indexes, reverse=True):\n",
    "            del lList[index]\n",
    "        for index in sorted(indexes, reverse=True):\n",
    "            del lList[index]             \n",
    "        return theDf\n",
    "    \n",
    "    def normalizeDataframe(self,theDf):\n",
    "        self.x = theDf.values\n",
    "        self.min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        self.x_scaled = self.min_max_scaler.fit_transform(self.x)\n",
    "        theDf = pd.DataFrame(self.x_scaled)\n",
    "        return theDf\n",
    "\n",
    "    def displayContour(self,theDf,contourIndex):\n",
    "        pass\n",
    "    \n",
    "a = arayi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Threaded feature extraction - Needs work\n",
    "\n",
    "'''\n",
    "NUM_WORKERS = 4\n",
    "processes = [multiprocessing.Process(target=a.extractMelody(pathToTrack,tList)) for _ in range(NUM_WORKERS)]\n",
    "print \"Starting Process\"\n",
    "[process.start() for process in processes]\n",
    "print \"Joining process\"\n",
    "[process.join() for process in processes]\n",
    "'''\n",
    "\n",
    "def threadMelodyExtract(self,pathToTrack,trackList):\n",
    "    ##TODO: Threading locks\n",
    "    threads = []\n",
    "    t=[]\n",
    "    for track in trackList:\n",
    "        if \".m4a\" not in track or \"_\" not in track:\n",
    "            continue\n",
    "        t = threading.Thread(target=a.extractMelody, args=(pathToTrack,track,))\n",
    "        threads.append(t)\n",
    "        if len(threads) > 9:\n",
    "            t.start()\n",
    "            t.join()\n",
    "            t=[]\n",
    "            threads=[]\n",
    "\n",
    "# def threadMelodyExtract2(self,pathToTrack,trackList):\n",
    "#     ##TODO: Threading locks\n",
    "#     lock = threading.Lock()\n",
    "#     threads = []\n",
    "#     for track in trackList:\n",
    "#         if \".m4a\" not in track or \"_\" not in track:\n",
    "#             continue\n",
    "#         t = threading.Thread(target=a.extractMelody, args=(pathToTrack,track,))\n",
    "#         lock.acquire()\n",
    "#         if not lock.acquire(False):\n",
    "#             print \"Fail\"\n",
    "#         else:\n",
    "#             try:\n",
    "#                 t.start()\n",
    "#                 t.join()\n",
    "#         finally:\n",
    "#             lock.release()\n",
    "            \n",
    "# arayi.threadMelodyExtract = threadMelodyExtract\n",
    "# arayi.threadMelodyExtract2 = threadMelodyExtract2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Functions\n",
    "pathToTrack = \"/Users/nus/singability_data/\"\n",
    "a = arayi()\n",
    "\n",
    "\n",
    "tracksAndLabels=a.getTracksAndLabels(pathToTrack,False,\"stay rihanna\")\n",
    "a.extractMelody(pathToTrack, tracksAndLabels.keys())\n",
    "# songDf,songLabels = a.cleanTrack(lList)\n",
    "\n",
    "df = a.makeContourDataframe(\"/Users/nus/singability_data/contours/stay/\")\n",
    "df.to_csv(\"/Users/nus/Documents/Github/Singability/data/stay.csv\", sep='\\t')\n",
    "# df=pd.read_csv(\"/Users/nus/Documents/Github/Singability/data/letItGo.csv\",sep=\"\\t\")\n",
    "# df=df.transpose()\n",
    "# df\n",
    "\n",
    "# df = a.excludeDataframeTracks(df,60,lList,tList)\n",
    "# df=df.replace(0, np.NaN)\n",
    "# dfNorm = a.normalizeDataframe(df)\n",
    "\n",
    "# x=dfNorm.index.values.tolist()\n",
    "# y=dfNorm[0].tolist()\n",
    "\n",
    "# x=df.index.values.tolist()\n",
    "# y=df[0].tolist()\n",
    "\n",
    "# matplotlib.pyplot.scatter(x,y,s=.1)\n",
    "# matplotlib.pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
