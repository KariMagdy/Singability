{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0582004439445\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import re\n",
    "import scipy.stats as sp\n",
    "import operator\n",
    "\n",
    "\n",
    "class arayi(object):\n",
    "    \n",
    "    def removeCols(self, csvPath):\n",
    "        df=pd.read_csv(csvPath)\n",
    "        dropCols = range(0,15)\n",
    "        dropCols += range(16,29)\n",
    "        df.drop(df.columns[dropCols],axis=1,inplace=True)\n",
    "        return df\n",
    "\n",
    "    def calcFAC(self,df):\n",
    "        facDict={}\n",
    "        for idx, row in df.iterrows():\n",
    "            ## Build dictionary with track keys\n",
    "            for cell in row[1:11]:\n",
    "                if cell.split(\"/\")[5] not in facDict:\n",
    "                    facDict[cell.split(\"/\")[5]]={\"familiar\":0,\"listen\":0,\"sing\":0}\n",
    "\n",
    "            ## Count number of times track is familiar\n",
    "            for loc, famil in enumerate(row[11:21]):\n",
    "                if famil == \"Y\":\n",
    "                    facDict[row[loc+1].split(\"/\")[5]][\"familiar\"]+=1\n",
    "\n",
    "            # Count number of times a song was preferred to listen\n",
    "            for loc, listen in enumerate(row[28:33]):\n",
    "                if listen == 1:\n",
    "                    header=\"Input.link%sa\" % str(loc+1)\n",
    "                    facDict[row[header].split(\"/\")[5]][\"listen\"]+=1\n",
    "                else:\n",
    "                    header=\"Input.link%sb\" % str(loc+1)\n",
    "                    facDict[row[header].split(\"/\")[5]][\"listen\"]+=1\n",
    "            \n",
    "            # Count number of times a song was preferred to be sung\n",
    "            for loc, sing in enumerate(row[51:56]):\n",
    "                if sing == 1:\n",
    "                    header=\"Input.link%sa\" % str(loc+1)\n",
    "                    facDict[row[header].split(\"/\")[5]][\"sing\"]+=1\n",
    "                else:\n",
    "                    header=\"Input.link%sb\" % str(loc+1)\n",
    "                    facDict[row[header].split(\"/\")[5]][\"sing\"]+=1\n",
    "\n",
    "        return facDict\n",
    "\n",
    "    def calcAHP(self,df):\n",
    "        ahpDict={\"globals\":{\"famil\":{\"genre\":[],\"repro\":[],\"listen\":[]},\"genre\":{\"listen\":[],\"repro\":[]},\"listen\":{\"repro\":[]}},\"locals\":{\"famil\":{\"Yes\":[]},\"listen\":{\"Low\":{\"Mid\":[],\"High\":[]},\"Mid\":{\"High\":[]}},\"repro\":{\"Easy\":{\"Mid\":[],\"Hard\":[]},\"Mid\":{\"Hard\":[]}},\"genre\":{\"Rock\":{\"Pop\":[],\"Alt\":[],\"Country\":[],\"Rap\":[]},\"Pop\":{\"Alt\":[],\"Country\":[],\"Rap\":[]},\"Alt\":{\"Country\":[],\"Rap\":[]},\"Country\":{\"Rap\":[]}}}}\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "\n",
    "            ## Globals\n",
    "            for ind,glob in enumerate(row[22:28]):\n",
    "                header = df.columns[ind+22].split(\"_\")[1]\n",
    "                if glob == 1:\n",
    "                    glob=0.0\n",
    "                else:\n",
    "                    glob=float(glob)\n",
    "\n",
    "                if np.sign(glob) == 1:\n",
    "                    try:\n",
    "                        ahpDict[\"globals\"][header.split(\"-\")[1]][header.split(\"-\")[0]].append(glob)\n",
    "                    except:\n",
    "                        ahpDict[\"globals\"][header.split(\"-\")[0]][header.split(\"-\")[1]].append(1/glob)\n",
    "                elif np.sign(glob) == -1:\n",
    "                    try:\n",
    "                        ahpDict[\"globals\"][header.split(\"-\")[0]][header.split(\"-\")[1]].append(abs(glob))\n",
    "                    except:\n",
    "                        ahpDict[\"globals\"][header.split(\"-\")[1]][header.split(\"-\")[0]].append(abs(1/glob))\n",
    "                else:\n",
    "                    try:\n",
    "                        ahpDict[\"globals\"][header.split(\"-\")[0]][header.split(\"-\")[1]].append(1.0)\n",
    "                    except:\n",
    "                        ahpDict[\"globals\"][header.split(\"-\")[1]][header.split(\"-\")[0]].append(1.0)\n",
    "\n",
    "            ## Locals\n",
    "#             print df.columns[33:50]\n",
    "            # Familiar\n",
    "            famLoc = float(row[33])\n",
    "            if np.sign(famLoc) < 0:\n",
    "                ahpDict[\"locals\"][\"famil\"][\"Yes\"].append(abs(famLoc))\n",
    "            elif np.sign(famLoc) > 0:\n",
    "                ahpDict[\"locals\"][\"famil\"][\"Yes\"].append(1/famLoc)\n",
    "            else:\n",
    "                ahpDict[\"locals\"][\"famil\"][\"Yes\"].append(1.0)\n",
    "        \n",
    "            # Genre\n",
    "            for dex,locs in enumerate(row[34:44]):\n",
    "                header=df.columns[dex+34].split(\"-\")[1]\n",
    "                header=re.findall(regexStr, header)\n",
    "                locs=float(locs)\n",
    "                if np.sign(locs) > 1:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"genre\"][header[1]][header[0]].append(locs)\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"genre\"][header[0]][header[1]].append(1/locs)\n",
    "                elif np.sign(locs) < 0:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"genre\"][header[0]][header[1]].append(abs(locs))\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"genre\"][header[1]][header[0]].append(1/abs(locs))\n",
    "                else:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"genre\"][header[0]][header[1]].append(1.0)\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"genre\"][header[1]][header[0]].append(1.0)\n",
    "                        \n",
    "            # Listen\n",
    "            for dex,locs in enumerate(row[44:47]):\n",
    "                header=df.columns[dex+44].split(\"-\")[1]\n",
    "                header=re.findall(regexStr,header)\n",
    "                locs=float(locs)\n",
    "                if np.sign(locs) > 1:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"listen\"][header[1]][header[0]].append(locs)\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"listen\"][header[0]][header[1]].append(1/locs)\n",
    "                elif np.sign(locs) < 0:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"listen\"][header[0]][header[1]].append(abs(locs))\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"listen\"][header[1]][header[0]].append(1/abs(locs))\n",
    "                else:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"listen\"][header[0]][header[1]].append(1.0)\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"listen\"][header[1]][header[0]].append(1.0)                    \n",
    "                        \n",
    "            # Repro\n",
    "            for dex,locs in enumerate(row[47:50]):\n",
    "                header=df.columns[dex+47].split(\"-\")[1]\n",
    "                header=re.findall(regexStr,header)\n",
    "                locs=float(locs)\n",
    "                if np.sign(locs) > 1:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"repro\"][header[1]][header[0]].append(float(locs))\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"repro\"][header[0]][header[1]].append(1/float(locs))\n",
    "                elif np.sign(locs) < 0:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"repro\"][header[0]][header[1]].append(float(abs(locs)))\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"repro\"][header[1]][header[0]].append(1/float(locs))                    \n",
    "                else:\n",
    "                    try:\n",
    "                        ahpDict[\"locals\"][\"repro\"][header[0]][header[1]].append(1.0)\n",
    "                    except:\n",
    "                        ahpDict[\"locals\"][\"repro\"][header[1]][header[0]].append(1.0)                                     \n",
    "        return ahpDict\n",
    "        \n",
    "    def makeAHPMatrix(self,df,globs):\n",
    "        for g in globs:\n",
    "            for glob in globs:\n",
    "                if g == glob:\n",
    "                    print g,glob,1.0                \n",
    "                elif g not in df[\"globals\"]:\n",
    "                    print g, glob, 1/np.mean(df[\"globals\"][glob][glob])\n",
    "                else:\n",
    "                    print g, glob, np.mean(df[\"globals\"][g][glob])\n",
    "        pass\n",
    "\n",
    "    def generateRanks(self, ahpValues, facValues):\n",
    "        sing={}\n",
    "        rankDict={}\n",
    "        globDic={}\n",
    "        \n",
    "        ## Generate ranks for FAC.  FAC ranks are the total amount of times a song is selected to sing\n",
    "        for song in facValues:\n",
    "            sing[song]=facValues[song]['sing']\n",
    "        sorted_sing = sorted(sing.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        for idx, ranks in enumerate(sorted_sing):\n",
    "            rankDict[ranks[0]]={\"billR\":int(ranks[0].split(\"_\")[0]),\"facR\":idx}\n",
    "        \n",
    "        ## Generate ranks for AHP. Values for each feature are calculated from familiarity, total listens, and genre scores\n",
    "        # Familiarity and Listens are categorized based on splitting each feature evenly across totals\n",
    "        for song in facDict:\n",
    "            sing[song]=facDict[song][\"familiar\"]\n",
    "        sorted_sing = sorted(sing.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        \n",
    "        for idx, ranks in enumerate(sorted_sing):\n",
    "            globDic[ranks[0]]={\"familiar\":None,\"genre\":None,\"listen\":None}\n",
    "\n",
    "            if idx < 26:\n",
    "                globDic[ranks[0]][\"familiar\"]=ahpValues[\"locals\"][\"famil\"][\"high\"]\n",
    "                globDic[ranks[0]][\"genre\"]=ahpValues[\"locals\"][\"genre\"][ranks[0].split(\"_\")[1]]\n",
    "            else:\n",
    "                globDic[ranks[0]][\"familiar\"]=ahpValues[\"locals\"][\"famil\"][\"low\"]\n",
    "                globDic[ranks[0]][\"genre\"]=ahpValues[\"locals\"][\"genre\"][ranks[0].split(\"_\")[1]]\n",
    "\n",
    "        for song in facDict:\n",
    "            sing[song]=facDict[song][\"listen\"]\n",
    "        sorted_sing = sorted(sing.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "        for idx, ranks in enumerate(sorted_sing):\n",
    "            if idx < 18:\n",
    "                globDic[ranks[0]][\"listen\"]=ahpValues[\"locals\"][\"listen\"][\"high\"]\n",
    "            elif idx >= 18 and idx > 36:\n",
    "                globDic[ranks[0]][\"listen\"]=ahpValues[\"locals\"][\"listen\"][\"mid\"]\n",
    "            else:\n",
    "                globDic[ranks[0]][\"listen\"]=ahpValues[\"locals\"][\"listen\"][\"low\"]\n",
    "\n",
    "        for song in globDic:\n",
    "            sing[song]=globDic[song][\"genre\"]*globDic[song][\"listen\"]*globDic[song][\"familiar\"]\n",
    "        sorted_sing = sorted(sing.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "\n",
    "        for idx, ranks in enumerate(sorted_sing):\n",
    "            rankDict[ranks[0]][\"ahpR\"]=idx\n",
    "        return rankDict\n",
    "            \n",
    "    def compareVoiceSex(self,data):\n",
    "        same=0\n",
    "        opposite=0\n",
    "        noCount=0\n",
    "        for idx, row in data.iterrows():\n",
    "            sex= row[50].lower()\n",
    "\n",
    "            for loc, sing in enumerate(row[51:56]):\n",
    "                s1=\"Input.link%sa\"% str(loc+1)\n",
    "                s2=\"Input.link%sb\"% str(loc+1)\n",
    "                song1=row[s1].split(\"_\")[2]\n",
    "                song2=row[s2].split(\"_\")[2]\n",
    "\n",
    "                if (song1 != song2):\n",
    "                    if sing == 1 and song1[0:1] == sex:\n",
    "                        same+=1\n",
    "                    elif sing == 2 and song2[0:1] == sex:\n",
    "                        same+=1\n",
    "                    else:\n",
    "                        opposite+=1\n",
    "                else:\n",
    "                    noCount+=1\n",
    "        print sp.binom_test([same,opposite],p=0.5)\n",
    "        \n",
    "a=arayi()\n",
    "regexStr='[A-Z][a-z]*'\n",
    "data=a.removeCols(\"/Users/nus/Documents/GitHub/Singability/data/mTurkResults.csv\")\n",
    "\n",
    "facDict=a.calcFAC(data)\n",
    "\n",
    "# ahpDict=a.calcAHP(data)\n",
    "\n",
    "ahpLocals={\"locals\":{\"genre\":{\"rock\":0.227694645,\"pop\":0.213700581,\"country\":0.193254532,\"alt\":0.196807281,\"rap\":0.168542961},\"famil\":{\"high\":0.613463796,\"low\":0.386536204},\"listen\":{\"low\":0.299476454,\"mid\":0.338568204,\"high\":0.361955342},\"repro\":{\"easy\":0.363546989,\"mid\":0.333072649,\"high\":0.303380363}}}\n",
    "rankDict=a.generateRanks(ahpLocals,facDict)\n",
    "\n",
    "a.compareVoiceSex(data)\n",
    "\n",
    "# for song in rankDict:\n",
    "#     billR.append(rankDict[song][\"billR\"])\n",
    "#     ahpR.append(rankDict[song][\"ahpR\"])\n",
    "#     facR.append(rankDict[song][\"facR\"])\n",
    "\n",
    "# # print rankDict\n",
    "# print \"AHP to Billboard:\", sp.spearmanr(ahpR,billR)\n",
    "# print \"FAC to Billboard:\", sp.spearmanr(facR,billR)\n",
    "# print \"AHP to FAC:\", sp.spearmanr(ahpR,facR)\n",
    "\n",
    "# print len(data['WorkerId'].unique())\n",
    "# print data.groupby('Answer.sex')['WorkerId'].nunique()\n",
    "\n",
    "\n",
    "globs=[\"famil\",\"genre\",\"repro\",\"listen\"]\n",
    "# ahpMat=a.makeAHPMatrix(ahpDict,globs)\n",
    "\n",
    "\n",
    "## Check ahp values\n",
    "# for key in ahpDict[\"globals\"]:\n",
    "#     for value in ahpDict[\"globals\"][key]:\n",
    "#         print key, value, np.mean(ahpDict[\"globals\"][key][value])\n",
    "\n",
    "# for key in ahpDict[\"locals\"]:\n",
    "#     if key==\"famil\":\n",
    "#         print \"local\", \"famil\",\"Yes\",\"Yes\",np.mean(ahpDict[\"locals\"][key][\"Yes\"])\n",
    "#         continue\n",
    "#     for level in ahpDict[\"locals\"][key]:\n",
    "#         for value in ahpDict[\"locals\"][key][level]:\n",
    "#             print \"local\", key,level,value, np.mean(ahpDict[\"locals\"][key][level][value])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25_41_49_rap_male_split.mp3\n",
      "11_16_49_country_female_split.mp3\n",
      "46_26_48_country_male_split.mp3\n",
      "33_22_42_alt_male_split.mp3\n",
      "39_18_49_pop_male_split.mp3\n",
      "27_45_47_rock_male_split.mp3\n",
      "38_40_50_country_female_split.mp3\n",
      "34_28_49_alt_female_split.mp3\n",
      "42_29_45_alt_male_split.mp3\n",
      "43_34_44_alt_female_split.mp3\n",
      "30_48_50_rock_female_split.mp3\n",
      "18_27_46_rap_male_split.mp3\n",
      "2_9_43_pop_male_split.mp3\n",
      "10_7_46_alt_female_split.mp3\n",
      "31_31_65_rock_female_split.mp3\n",
      "12_11_46_country_male_split.mp3\n",
      "3_2_41_pop_female_split.mp3\n",
      "41_25_50_rap_female_split.mp3\n",
      "4_3_42_pop_male_split.mp3\n",
      "24_37_43_rap_male_split.mp3\n",
      "28_42_49_rock_male_split.mp3\n",
      "5_6_42_pop_female_split.mp3\n",
      "49_49_45_rap_female_split.mp3\n",
      "44_36_50_alt_male_split.mp3\n",
      "22_23_44_country_female_split.mp3\n",
      "15_15_41_rock_female_split.mp3\n",
      "50_46_48_rap_male_split.mp3\n",
      "6_12_44_pop_female_split.mp3\n",
      "7_5_41_pop_male_split.mp3\n",
      "23_32_44_country_male_split.mp3\n",
      "26_13_41_rap_male_split.mp3\n",
      "19_8_41_rap_female_split.mp3\n",
      "17_24_48_pop_female_split.mp3\n",
      "20_17_46_rap_female_split.mp3\n",
      "29_47_42_rock_male_split.mp3\n",
      "37_50_41_alt_female_split.mp3\n",
      "8_14_43_pop_female_split.mp3\n",
      "16_21_43_rock_female_split.mp3\n",
      "13_10_42_country_female_split.mp3\n",
      "35_43_47_alt_female_split.mp3\n",
      "40_35_50_pop_male_split.mp3\n",
      "14_19_45_country_female_split.mp3\n",
      "32_39_45_rock_male_split.mp3\n",
      "21_4_42_rap_female_split.mp3\n",
      "47_30_50_country_male_split.mp3\n",
      "9_33_43_rock_male_split.mp3\n",
      "1_1_33_rock_female_split.mp3\n",
      "36_44_43_alt_male_split.mp3\n",
      "45_38_47_alt_male_split.mp3\n",
      "48_20_42_country_male_split.mp3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "billR,ahpR,facR=[],[],[]\n",
    "for song in rankDict:\n",
    "    newName= \"_\".join(map(str,[rankDict[song][\"ahpR\"]+1,rankDict[song][\"facR\"]+1, song]))\n",
    "    print newName\n",
    "    command = \"cp /Users/nus/Documents/GitHub/singability/data/splits/male/%s /Users/nus/Documents/GitHub/singability/data/splits/ranked/%s\" % (song,newName)\n",
    "    os.system(command)\n",
    "# for song in rankDict:\n",
    "#     billR.append(rankDict[song][\"billR\"])\n",
    "#     ahpR.append(rankDict[song][\"ahpR\"])\n",
    "#     facR.append(rankDict[song][\"facR\"])\n",
    "    \n",
    "# print \"AHP to Billboard:\", sp.spearmanr(ahpR,billR)\n",
    "# print \"FAC to Billboard:\", sp.spearmanr(facR,billR)\n",
    "# print \"AHP to FAC:\", sp.spearmanr(ahpR,facR)\n",
    "\n",
    "# x=range(1,len(facR)+1)\n",
    "# billR2=[i for i,j in enumerate(billR)]\n",
    "# print len(x),len(billR2),len(facR),len(ahpR)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# fit= np.polyfit(ahpR,facR, deg=1)\n",
    "# fit_fn = np.poly1d(fit)\n",
    "# plt.scatter(ahpR,facR)\n",
    "# plt.plot(ahpR, fit_fn(ahpR),color=\"red\")\n",
    "# plt.annotate(\"r=0.6988\", xy=(23, 20),size=10)\n",
    "\n",
    "# plt.xlabel(\"AHP Rank\")\n",
    "# plt.ylabel(\"FAC Rank\")\n",
    "# plt.title(\"AHP to FAC Rank Correlation\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(\"/Users/nus/Documents/GitHub/Singability/data/images/ahpFacCorr.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, 0.0, nan, 0.0, 0.0]\n",
      "[-0.36363636363636354, 0.54545454545454541, -0.15384615384615374, 0.0, 0.0, -0.25, 0.2857142857142857, 0.0, 0.0, -0.4285714285714286, 0.0, 0.0, 0.0, 0.0, nan]\n",
      "[0.0, 0.0, 0.0, nan, -0.15384615384615374, -0.66666666666666674, 0.0, 0.61538461538461542, 0.0, 0.0]\n",
      "[nan, nan, nan]\n",
      "[nan, 0.0, 0.0, 0.0, 0.0, 0.54545454545454541]\n",
      "[0.0, nan, 0.0]\n",
      "[-0.36363636363636354, 0.0, 0.0, 0.0, 0.0, nan]\n",
      "[0.0, 0.0, 0.16666666666666663, -0.15384615384615374, nan, 0.0, 0.0, 0.0, 0.0, -0.15384615384615374]\n",
      "[0.0, 0.0, nan]\n",
      "[-0.25, 0.0, 0.54545454545454541, 0.0, 0.0, 0.54545454545454541, 0.0, 0.0, nan, 0.0]\n",
      "Nan? [-0.065476190476190479, -0.26984126984126988, 0.04373404373404375, -0.0024509803921568172, 0.0079365079365079083, Exception('Nan?',), -0.36904761904761907, Exception('Nan?',), -0.18686868686868682, 0.74358974358974361, -0.14909110497345787, 0.20512820512820515, -0.18686868686868682, 0.2857142857142857, -0.11111111111111116, 0.055555555555555546, 0.22577422577422579, -0.38888888888888901, -0.051282051282051246, 0.52380952380952372, 0.16666666666666666, -0.32478632478632474, 0.1818181818181818, -0.022727272727272707, 0.055555555555555546, -0.034188034188034178, 0.24603174603174602, 0.16666666666666663, -0.32575757575757569, -0.051282051282051246, -0.11111111111111116, -0.051282051282051246, -0.14285714285714288, 0.52380952380952372, -0.32478632478632474, -0.12121212121212117, -0.22222222222222224, 0.48218448218448212, 0.039215686274509852, 0.20940170940170943, 0.69696969696969691, -0.065476190476190479, 0.10470085470085472, 0.055555555555555546, 0.52380952380952372, -0.33366633366633353, Exception('Nan?',), 0.17915417915417919, -0.14285714285714288, -0.051282051282051246, -0.038628038628038597, Exception('Nan?',), 0.095238095238095233, 0.10470085470085472, 0.091880341880341942, -0.077256077256077194, -0.092171717171717168, 0.48218448218448212, 0.1818181818181818, -0.022727272727272707, -0.077256077256077194, 0.48218448218448212, 0.48218448218448212, 0.24603174603174602, 0.29915917415917415, -0.12121212121212117, 0.26119174942704354, 0.11288711288711289, 0.23076923076923084, -0.092171717171717168, -0.012321012321012311, -0.051282051282051246, -0.27136752136752135, 0.11288711288711289, -0.012321012321012311, -0.33366633366633353, 0.20512820512820515, -0.16161616161616163, 0.20940170940170943, 0.039215686274509852, 0.17915417915417919, 0.33333333333333331, -0.083333333333333329, 0.23076923076923084, -0.12776112776112775, 0.24603174603174602, -0.1124267888973771, -0.30341880341880334, -0.13095238095238096, 0.20512820512820515, -0.16161616161616163, 0.20940170940170943, Exception('Nan?',), 0.74358974358974361, 0.48218448218448212, -0.32478632478632474, 0.20512820512820515, 0.095238095238095233, -0.022727272727272707, 0.1818181818181818, 0.16666666666666666, -0.13095238095238096, 0.23076923076923084, -0.023504273504273476, -0.20365745365745366, 0.24109224109224106, -0.083333333333333329, 0.095238095238095233, 0.20940170940170943, 0.3448218448218448, 0.027272727272727292, 0.22222222222222221, 0.09873459873459875, 0.089577089577089597, 0.24603174603174602, 0.34469696969696967, 0.20940170940170943, -0.16161616161616163, -0.30341880341880334, -0.12121212121212117, 0.20512820512820515, -0.12121212121212117, 0.44444444444444436, -0.12121212121212117, -0.36904761904761907, 0.46581196581196577, 0.053571428571428568, 0.20959595959595956, -0.093434343434343411, -0.15767565767565764, 0.0079365079365079083, -0.077256077256077194, -0.14285714285714288, 0.52380952380952384, -0.26984126984126988, -0.051282051282051246, -0.038628038628038597, 0.20588235294117652, -0.18686868686868682, -0.13095238095238096, 0.013241660300483904, -0.077256077256077194, -0.061507936507936532, 0.065656565656565635, -0.32478632478632474, -0.24680874680874676, 0.22577422577422579, -0.1124267888973771, 0.045454545454545491, 0.31627196333078689, 0.24603174603174602, 0.063575313575313597, -0.2301587301587302, -0.012321012321012311, -0.13095238095238096, 0.48218448218448212, -0.029470529470529454, -0.066653934300993062, -0.0049019607843136343, -0.12121212121212117, 0.74358974358974361, -0.12121212121212117, 0.20512820512820515, -0.11111111111111116, 0.11616161616161617, 0.032051282051282062, Exception('Nan?',), -0.077256077256077194, Exception('Nan?',), -0.11111111111111116, 0.33333333333333331, -0.22222222222222224, -0.012321012321012311, -0.11111111111111116, -0.14316239316239315, -0.086866564807741228, 0.095238095238095233, 0.095238095238095233, -0.46464646464646459, -0.14285714285714288, 0.33333333333333331, -0.068376068376068355, -0.05555555555555558, 0.74358974358974361, 0.44444444444444436, 0.095238095238095233, 0.0, 0.1818181818181818, 0.39922822275763453, 0.69696969696969691, -0.065476190476190479, 0.17915417915417919, 0.041791541791541854, 0.33333333333333331, -0.36904761904761907, 0.1818181818181818, 0.24109224109224106, 0.038789152024446175, 0.23290598290598288, 0.16666666666666666, 0.22577422577422579, -0.022727272727272707, -0.12121212121212117, 0.31627196333078689, -0.18686868686868682, -0.25, -0.051282051282051246, -0.022727272727272707, -0.18589743589743582, 0.11616161616161617, 0.24109224109224106, 0.034940059940059956, -0.12121212121212117, -0.083333333333333329, -0.022727272727272707, 0.74358974358974361, Exception('Nan?',), -0.11111111111111116, 0.055555555555555546, -0.012321012321012311, 0.31082806082806086, -0.12121212121212117, -0.36904761904761907, 0.20512820512820515, -0.077256077256077194, 0.1818181818181818, Exception('Nan?',), Exception('Nan?',), 0.0079365079365079083, -0.0049019607843136343, 0.77272727272727282, -0.13095238095238096, 0.23290598290598288, 0.055555555555555546, 0.48218448218448212, 0.20940170940170941, -0.18686868686868682, 0.1818181818181818, 0.063575313575313597, 0.095238095238095233, -0.20098039215686267, 0.17915417915417919, -0.18283677107206511, -0.071428571428571438, -0.051282051282051246]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def removeColsKappa(self, csvPath):\n",
    "    df=pd.read_csv(csvPath)\n",
    "    dropCols = range(1,79)\n",
    "    dropCols += range(84,86)\n",
    "    df.drop(df.columns[dropCols],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def avgKappa(valueList):\n",
    "    resultList=[]\n",
    "    perms=list(itertools.combinations(valueList,2))\n",
    "    for perm in perms:\n",
    "        resultList.append(cohen_kappa_score(perm[0], perm[1]))\n",
    "    if math.isnan(np.mean(resultList)) == True :\n",
    "        print resultList\n",
    "        return Exception(\"Nan?\")\n",
    "    return np.mean(resultList)\n",
    "\n",
    "arayi.removeColsKappa = removeColsKappa\n",
    "arayi.avgKappa=avgKappa\n",
    "a=arayi()\n",
    "\n",
    "regexStr='[A-Z][a-z]*'\n",
    "data=a.removeColsKappa(\"/Users/nus/Documents/GitHub/Singability/data/mTurkResults.csv\")\n",
    "\n",
    "index=0\n",
    "kappa={}\n",
    "for row in data.iterrows():\n",
    "    if row[1][0] not in kappa:\n",
    "        kappa[row[1][0]]=[list(row[1][1:6])]\n",
    "    else:\n",
    "        kappa[row[1][0]].append(list(row[1][1:6]))\n",
    "\n",
    "\n",
    "kappaList=[]\n",
    "for key in kappa.keys():\n",
    "    kappaList.append(avgKappa(kappa[key]))\n",
    "print max(kappaList), kappaList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
