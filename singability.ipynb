{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded\n"
     ]
    }
   ],
   "source": [
    "# Load required packages\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "# from sklearn import preprocessing\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "# import threading\n",
    "# import multiprocessing\n",
    "# import pickle\n",
    "# import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "print \"Packages loaded\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Functions for feature extraction\n",
    "class arayi(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    # Get list of tracks for extraction\n",
    "    def getTrackList(self,pathToTrack,listBool,trackName):\n",
    "        if listBool == False:\n",
    "            self.filelist=[]\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    tName,language=line[2].replace(\"_\",\" \").lstrip().rstrip(),line[6].rstrip()\n",
    "                    if (tName == trackName and language == \"EN\"):\n",
    "                        self.filelist.append(line[1])\n",
    "            return self.filelist\n",
    "        else:\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "\n",
    "    def getLabelList(self,pathToTrack,listBool,trackName):\n",
    "        if listBool == False:\n",
    "            self.filelist=[]\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    if (line[2].replace(\"_\",\" \").lstrip().rstrip() == trackName and line[6].rstrip() == \"EN\"):\n",
    "                        self.filelist.append(line[5])\n",
    "            return self.filelist\n",
    "        else:\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "        \n",
    "    def getTracksAndLabels(self,pathtoTrack,listBool,trackName):\n",
    "        self.dataDict={}\n",
    "        if listBool == False:\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    if (line[2].replace(\"_\",\" \").lstrip().rstrip() == trackName and line[6].rstrip() == \"EN\"):\n",
    "                        self.dataDict[line[1]]=line[5]\n",
    "            return self.dataDict\n",
    "        else:\n",
    "            self.filelist=[]\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "        \n",
    "    # Extract Melodic Contours from Dataset\n",
    "    def extractMelody(self, pathToTrack,trackList):\n",
    "        self.extractStatus = 0.0\n",
    "        pathToTrack = pathToTrack+\"raw/\"\n",
    "        # Extracts contour for a track snd saves output for each track\n",
    "        for track in trackList:\n",
    "            self.trackOut = \"/Users/nus/singability_data/contours/%s.yml\" % track.split(\".\")[0]\n",
    "            os.system(\"essentia_streaming_predominantpitchmelodia %s %s\" % (pathToTrack+track+\".m4a\", self.trackOut))\n",
    "            if float(trackList.index(track)+1)/len(trackList) > self.extractStatus:\n",
    "                print \"Extracting...%s %% complete.\" % (self.extractStatus*100)\n",
    "                self.extractStatus += 0.33\n",
    "                \n",
    "    def cleanTrack(self,labelList):\n",
    "        df = pickle.load(open(\"/Users/nus/singability_data/letItGo.pkl\",\"rb\"))\n",
    "        df=df.transpose()\n",
    "        self.lList=[]\n",
    "        for col in df:\n",
    "            numNull=df[col].isnull().sum()\n",
    "            if numNull > 60:\n",
    "                df.drop(col,1,inplace=True)\n",
    "                self.lList.append(col)\n",
    "        df.fillna(0)\n",
    "        labelList=[x for i,x in enumerate(labelList) if i not in lList]\n",
    "        return (df,labelList)\n",
    "\n",
    "    def makeContourDataframe(self,pathToContours):\n",
    "        cList=os.listdir(pathToContours)\n",
    "        self.contourMatrix = {}\n",
    "        for contour in cList:\n",
    "            if \".yml\" not in contour:\n",
    "                continue\n",
    "            x=list(open(pathToContours+contour,\"r\"))\n",
    "            x=map(float,x[7].lstrip().replace(\"pitch: \",\"\").replace(\"[\",\"\").replace(\"]\",\"\").split(\",\"))\n",
    "            self.contourMatrix[contour.replace(\".yml\",\"\")]=x\n",
    "        df = pd.DataFrame.from_dict(self.contourMatrix,orient=\"index\")\n",
    "        return df\n",
    "\n",
    "    def excludeDataframeTracks(self,theDf,window,lList,tList):\n",
    "        indexes=[]\n",
    "        for col in theDf:\n",
    "            numNull=theDf[col].isnull().sum()\n",
    "            if numNull > window:\n",
    "                theDf.drop(col,1,inplace=True)\n",
    "                indexes.append(col)\n",
    "        print indexes\n",
    "        for index in sorted(indexes, reverse=True):\n",
    "            del lList[index]\n",
    "        for index in sorted(indexes, reverse=True):\n",
    "            del tList[index]             \n",
    "        return theDf,lList,tList\n",
    "    \n",
    "    def normalizeDataframe(self,theDf):\n",
    "        self.x = theDf.values\n",
    "        self.min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        self.x_scaled = self.min_max_scaler.fit_transform(self.x)\n",
    "        theDf = pd.DataFrame(self.x_scaled)\n",
    "        return theDf\n",
    "\n",
    "    def displayContour(self,theDf,contourIndex):\n",
    "        pass\n",
    "    \n",
    "a = arayi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Threaded feature extraction - Needs work\n",
    "\n",
    "'''\n",
    "NUM_WORKERS = 4\n",
    "processes = [multiprocessing.Process(target=a.extractMelody(pathToTrack,tList)) for _ in range(NUM_WORKERS)]\n",
    "print \"Starting Process\"\n",
    "[process.start() for process in processes]\n",
    "print \"Joining process\"\n",
    "[process.join() for process in processes]\n",
    "'''\n",
    "\n",
    "def threadMelodyExtract(self,pathToTrack,trackList):\n",
    "    ##TODO: Threading locks\n",
    "    threads = []\n",
    "    t=[]\n",
    "    for track in trackList:\n",
    "        if \".m4a\" not in track or \"_\" not in track:\n",
    "            continue\n",
    "        t = threading.Thread(target=a.extractMelody, args=(pathToTrack,track,))\n",
    "        threads.append(t)\n",
    "        if len(threads) > 9:\n",
    "            t.start()\n",
    "            t.join()\n",
    "            t=[]\n",
    "            threads=[]\n",
    "\n",
    "# def threadMelodyExtract2(self,pathToTrack,trackList):\n",
    "#     ##TODO: Threading locks\n",
    "#     lock = threading.Lock()\n",
    "#     threads = []\n",
    "#     for track in trackList:\n",
    "#         if \".m4a\" not in track or \"_\" not in track:\n",
    "#             continue\n",
    "#         t = threading.Thread(target=a.extractMelody, args=(pathToTrack,track,))\n",
    "#         lock.acquire()\n",
    "#         if not lock.acquire(False):\n",
    "#             print \"Fail\"\n",
    "#         else:\n",
    "#             try:\n",
    "#                 t.start()\n",
    "#                 t.join()\n",
    "#         finally:\n",
    "#             lock.release()\n",
    "            \n",
    "# arayi.threadMelodyExtract = threadMelodyExtract\n",
    "# arayi.threadMelodyExtract2 = threadMelodyExtract2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Functions\n",
    "pathToTrack = \"/Users/nus/singability_data/\"\n",
    "a = arayi()\n",
    "\n",
    "songs=[\"let it go\",\"stay rihanna\"]\n",
    "\n",
    "# tracksAndLabels=a.getTracksAndLabels(pathToTrack,False,\"let it go\")\n",
    "# lList=tracksAndLabels.values()\n",
    "# tList=tracksAndLabels.keys()\n",
    "\n",
    "# plt.scatter(x=range(0,len(tracksAndLabels)),y=np.log(sorted(map(float,tracksAndLabels.values()))),s=1)\n",
    "# plt.show()\n",
    "\n",
    "# a.extractMelody(pathToTrack, tracksAndLabels.keys())\n",
    "# songDf,songLabels = a.cleanTrack(lList)\n",
    "\n",
    "# df = a.makeContourDataframe(\"/Users/nus/singability_data/contours/stay/\")\n",
    "# df.to_csv(\"/Users/nus/Documents/Github/Singability/data/stay.csv\", sep='\\t')\n",
    "df=pd.read_csv(\"/Users/nus/Documents/Github/Singability/data/letItGo.csv\",sep=\"\\t\",header=0)\n",
    "df=df.transpose()\n",
    "df.columns=df.iloc[0]\n",
    "df=df[1:]\n",
    "df=df.iloc[:,1:]\n",
    "# print tList\n",
    "df, lList, tList = a.excludeDataframeTracks(df,60,lList,tList)\n",
    "\n",
    "# df\n",
    "# df=df.replace(0, np.NaN)\n",
    "# df.to_csv(\"/Users/nus/Documents/Github/Singability/data/letItGo_cleaned.csv\", sep='\\t')\n",
    "# df=pd.read_csv(\"/Users/nus/Documents/Github/Singability/data/letItGo_cleaned.csv\",sep=\"\\t\",header=0)\n",
    "# df\n",
    "# print \"complete\"\n",
    "# dfNorm = a.normalizeDataframe(df)\n",
    "\n",
    "# x=dfNorm.index.values.tolist()\n",
    "# y=dfNorm[0].tolist()\n",
    "\n",
    "# x=df.index.values.tolist()\n",
    "# y=df.iloc[0,:].tolist()\n",
    "\n",
    "# print len(tList)\n",
    "# plt.scatter(range(0,len(tList)),sorted(np.log(map(float,lList))),s=.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# df = pd.DataFrame(data=np.random.normal(0, 1, (20, 10)))\n",
    "# df=df.replace(np.NaN, 0)\n",
    "\n",
    "# pca = PCA(n_components=\"mle\",svd_solver=\"full\")\n",
    "# pca.fit(df)\n",
    "# comps=pca.components_ \n",
    "dfPCA=df\n",
    "\n",
    "# [len(x) for x in comps]\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
