{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded\n"
     ]
    }
   ],
   "source": [
    "# Load required packages\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import threading\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "print \"Packages loaded\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Functions for feature extraction\n",
    "class arayi(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    # Get list of tracks for extraction\n",
    "    def getTrackList(self,pathToTrack,listBool,trackName):\n",
    "        if listBool == False:\n",
    "            self.filelist=[]\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    tName,language=line[2].replace(\"_\",\" \").lstrip().rstrip(),line[6].rstrip()\n",
    "                    if (tName == trackName and language == \"EN\"):\n",
    "                        self.filelist.append(line[1])\n",
    "            return self.filelist\n",
    "        else:\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "\n",
    "    def getLabelList(self,pathToTrack,listBool,trackName):\n",
    "        if listBool == False:\n",
    "            self.filelist=[]\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    if (line[2].replace(\"_\",\" \").lstrip().rstrip() == trackName and line[6].rstrip() == \"EN\"):\n",
    "                        self.filelist.append(line[5])\n",
    "            return self.filelist\n",
    "        else:\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "        \n",
    "    def getTracksAndLabels(self,pathtoTrack,listBool,trackName):\n",
    "        self.dataDict={}\n",
    "        if listBool == False:\n",
    "            with open(pathToTrack+\"/metadata/perfs.csv\",\"r\") as perfData:\n",
    "                perfData.next()\n",
    "                for line in perfData:\n",
    "                    line=line.split(\",\")\n",
    "                    if (line[2].replace(\"_\",\" \").lstrip().rstrip() == trackName and line[6].rstrip() == \"EN\"):\n",
    "                        self.dataDict[line[1]]=line[5]\n",
    "            return self.dataDict\n",
    "        else:\n",
    "            self.filelist=[]\n",
    "            self.filelist = os.listdir(pathToTrack)            \n",
    "            return self.filelist\n",
    "        \n",
    "    # Extract Melodic Contours from Dataset\n",
    "    def extractMelody(self, pathToTrack,trackList):\n",
    "        self.extractStatus = 0.0\n",
    "        pathToTrack = pathToTrack+\"raw/\"\n",
    "        # Extracts contour for a track snd saves output for each track\n",
    "        for track in trackList:\n",
    "            self.trackOut = \"/Users/nus/singability_data/contours/%s.yml\" % track.split(\".\")[0]\n",
    "            os.system(\"essentia_streaming_predominantpitchmelodia %s %s\" % (pathToTrack+track+\".m4a\", self.trackOut))\n",
    "            if float(trackList.index(track)+1)/len(trackList) > self.extractStatus:\n",
    "                print \"Extracting...%s %% complete.\" % (self.extractStatus*100)\n",
    "                self.extractStatus += 0.33\n",
    "                \n",
    "    def cleanTrack(self,labelList):\n",
    "        df = pickle.load(open(\"/Users/nus/singability_data/letItGo.pkl\",\"rb\"))\n",
    "        df=df.transpose()\n",
    "        self.lList=[]\n",
    "        for col in df:\n",
    "            numNull=df[col].isnull().sum()\n",
    "            if numNull > 60:\n",
    "                df.drop(col,1,inplace=True)\n",
    "                self.lList.append(col)\n",
    "        df.fillna(0)\n",
    "        labelList=[x for i,x in enumerate(labelList) if i not in lList]\n",
    "        return (df,labelList)\n",
    "\n",
    "    def makeContourDataframe(self,pathToContours):\n",
    "        cList=os.listdir(pathToContours)\n",
    "        self.contourMatrix = {}\n",
    "        for contour in cList:\n",
    "            if \".yml\" not in contour:\n",
    "                continue\n",
    "            x=list(open(pathToContours+contour,\"r\"))\n",
    "            x=map(float,x[7].lstrip().replace(\"pitch: \",\"\").replace(\"[\",\"\").replace(\"]\",\"\").split(\",\"))\n",
    "            self.contourMatrix[contour.replace(\".yml\",\"\")]=x\n",
    "        df = pd.DataFrame.from_dict(self.contourMatrix,orient=\"index\")\n",
    "        return df\n",
    "\n",
    "    def excludeDataframeTracks(self,theDf,window,lList,tList):\n",
    "        indexes=[]\n",
    "        for col in theDf:\n",
    "            numNull=theDf[col].isnull().sum()\n",
    "            if numNull > window:\n",
    "                theDf.drop(col,1,inplace=True)\n",
    "                indexes.append(col)\n",
    "        for index in sorted(indexes, reverse=True):\n",
    "            del lList[index]\n",
    "        for index in sorted(indexes, reverse=True):\n",
    "            del tList[index]             \n",
    "        return theDf\n",
    "    \n",
    "    def normalizeDataframe(self,theDf):\n",
    "        self.x = theDf.values\n",
    "        self.min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        self.x_scaled = self.min_max_scaler.fit_transform(self.x)\n",
    "        theDf = pd.DataFrame(self.x_scaled)\n",
    "        return theDf\n",
    "\n",
    "    def displayContour(self,theDf,contourIndex):\n",
    "        pass\n",
    "    \n",
    "a = arayi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Threaded feature extraction - Needs work\n",
    "\n",
    "'''\n",
    "NUM_WORKERS = 4\n",
    "processes = [multiprocessing.Process(target=a.extractMelody(pathToTrack,tList)) for _ in range(NUM_WORKERS)]\n",
    "print \"Starting Process\"\n",
    "[process.start() for process in processes]\n",
    "print \"Joining process\"\n",
    "[process.join() for process in processes]\n",
    "'''\n",
    "\n",
    "def threadMelodyExtract(self,pathToTrack,trackList):\n",
    "    ##TODO: Threading locks\n",
    "    threads = []\n",
    "    t=[]\n",
    "    for track in trackList:\n",
    "        if \".m4a\" not in track or \"_\" not in track:\n",
    "            continue\n",
    "        t = threading.Thread(target=a.extractMelody, args=(pathToTrack,track,))\n",
    "        threads.append(t)\n",
    "        if len(threads) > 9:\n",
    "            t.start()\n",
    "            t.join()\n",
    "            t=[]\n",
    "            threads=[]\n",
    "\n",
    "# def threadMelodyExtract2(self,pathToTrack,trackList):\n",
    "#     ##TODO: Threading locks\n",
    "#     lock = threading.Lock()\n",
    "#     threads = []\n",
    "#     for track in trackList:\n",
    "#         if \".m4a\" not in track or \"_\" not in track:\n",
    "#             continue\n",
    "#         t = threading.Thread(target=a.extractMelody, args=(pathToTrack,track,))\n",
    "#         lock.acquire()\n",
    "#         if not lock.acquire(False):\n",
    "#             print \"Fail\"\n",
    "#         else:\n",
    "#             try:\n",
    "#                 t.start()\n",
    "#                 t.join()\n",
    "#         finally:\n",
    "#             lock.release()\n",
    "            \n",
    "# arayi.threadMelodyExtract = threadMelodyExtract\n",
    "# arayi.threadMelodyExtract2 = threadMelodyExtract2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Functions\n",
    "pathToTrack = \"/Users/nus/singability_data/\"\n",
    "a = arayi()\n",
    "\n",
    "songs=[\"let it go\",\"stay rihanna\"]\n",
    "\n",
    "# tracksAndLabels=a.getTracksAndLabels(pathToTrack,False,\"let it go\")\n",
    "# lList=tracksAndLabels.values()\n",
    "# tList=tracksAndLabels.keys()\n",
    "# plt.scatter(x=range(0,len(tracksAndLabels)),y=np.log(sorted(map(float,tracksAndLabels.values()))),s=1)\n",
    "# plt.show()\n",
    "\n",
    "# a.extractMelody(pathToTrack, tracksAndLabels.keys())\n",
    "# songDf,songLabels = a.cleanTrack(lList)\n",
    "\n",
    "# df = a.makeContourDataframe(\"/Users/nus/singability_data/contours/stay/\")\n",
    "# df.to_csv(\"/Users/nus/Documents/Github/Singability/data/stay.csv\", sep='\\t')\n",
    "# df=pd.read_csv(\"/Users/nus/Documents/Github/Singability/data/letItGo.csv\",sep=\"\\t\",header=0)\n",
    "# df=df.transpose()\n",
    "# df.columns=df.iloc[0]\n",
    "# df=df[1:]\n",
    "\n",
    "# df = a.excludeDataframeTracks(df,60,lList,tList)\n",
    "# df\n",
    "# df=df.replace(0, np.NaN)\n",
    "# df.to_csv(\"/Users/nus/Documents/Github/Singability/data/letItGo_cleaned.csv\", sep='\\t')\n",
    "# dfNorm = a.normalizeDataframe(df)\n",
    "\n",
    "# x=dfNorm.index.values.tolist()\n",
    "# y=dfNorm[0].tolist()\n",
    "\n",
    "#x=df.index.values.tolist()\n",
    "#y=df[0].tolist()\n",
    "\n",
    "#plt.scatter(x,y,s=.1)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for float(): 174605100_34286363",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d8ba86c23a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m '''\n",
      "\u001b[0;32m/Users/nus/anaconda/envs/singability/lib/python2.7/site-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \"\"\"\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nus/anaconda/envs/singability/lib/python2.7/site-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 366\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nus/anaconda/envs/singability/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for float(): 174605100_34286363"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# df = pd.DataFrame(data=np.random.normal(0, 1, (20, 10)))\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(df)\n",
    "\n",
    "'''\n",
    "myAudio=\"/Users/nus/Desktop/68366569_39548661_1.wav\"\n",
    "\n",
    "y, sr = librosa.load(myAudio)\n",
    "librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(S,ref=np.max),y_axis='mel', fmax=8000,x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
